<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Power, Temperature, &amp;amp; Noise - The NVIDIA GeForce GTX Titan X Review | WinkVibe</title><meta name=generator content="Hugo 0.98.0"><meta name=description content="Power, Temperature, & Noise As always, last but not least is our look at power, temperature, and noise. Next to price and performance of course, these are some of the most important aspects of a GPU, due in large part to the impact of noise. All things considered, a loud card is undesirable unless there’s a sufficiently good reason – or sufficiently good performance – to ignore the noise.
The GTX Titan X represents a very interesting intersection for NVIDIA, crossing Maxwell’s unparalleled power efficiency with GTX Titan’s flagship level performance goals and similarly high power allowance."><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/normalize.css><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel=stylesheet type=text/css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/cayman.css><link rel=apple-touch-icon sizes=180x180 href=./apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=./favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=./favicon-16x16.png><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css integrity=sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js integrity=sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script></head><body><section class=page-header><h1 class=project-name>WinkVibe</h1><h2 class=project-tagline></h2><nav><a href=./index.html class=btn>Blog</a>
<a href=./sitemap.xml class=btn>Sitemap</a>
<a href=./index.xml class=btn>RSS</a></nav></section><section class=main-content><h1>Power, Temperature, &amp;amp; Noise - The NVIDIA GeForce GTX Titan X Review</h1><div><strong>Publish date: </strong>2024-06-27</div><h2>Power, Temperature, & Noise</h2><p>As always, last but not least is our look at power, temperature, and noise. Next to price and performance of course, these are some of the most important aspects of a GPU, due in large part to the impact of noise. All things considered, a loud card is undesirable unless there’s a sufficiently good reason – or sufficiently good performance – to ignore the noise.</p><p>The GTX Titan X represents a very interesting intersection for NVIDIA, crossing Maxwell’s unparalleled power efficiency with GTX Titan’s flagship level performance goals and similarly high power allowance. The end result is that this gives us a chance to see how well Maxwell holds up when pushed to the limit; to see how well the architecture holds up in the form of a 601mm2 GPU with a 250W TDP.</p><table align=center border=0 cellpadding=0 cellspacing=1 width=600><tbody readability=2><tr class=tgrey readability=2><td align=center colspan=5>GeForce GTX Titan X Voltages</td></tr><tr class=tlblue readability=2><td align=center valign=middle width=85>GTX Titan X Boost Voltage</td><td align=center valign=middle width=85>GTX 980 Boost Voltage</td><td align=center valign=middle width=85>GTX Titan X Idle Voltage</td></tr><tr><td align=center valign=middle>1.162v</td><td align=center valign=middle>1.225v</td><td align=center valign=middle>0.849v</td></tr></tbody></table><p>Starting off with voltages, based on our samples we find that NVIDIA has been rather conservative in their voltage allowance, presumably to keep power consumption down. With the highest stock boost bin hitting a voltage of just 1.162v, GTX Titan X operates notably lower on the voltage curve than the GTX 980. This goes hand-in-hand with GTX Titan X’s stock clockspeeds, which are around 100MHz lower than GTX 980.</p><table align=center border=0 cellpadding=0 cellspacing=1 width=454><tbody readability=1><tr class=tgrey readability=2><td align=center colspan=4>GeForce GTX Titan X Average Clockspeeds</td></tr><tr class=tlblue><td align=center valign=middle width=150>Game</td><td align=center valign=middle width=150>GTX Titan X</td><td align=center valign=middle width=150>GTX 980</td></tr><tr><td class=tlgrey>Max Boost Clock</td><td align=center valign=middle>1215MHz</td><td align=center valign=middle>1252MHz</td></tr><tr><td class=tlgrey>Battlefield 4</td><td><p>1088MHz</p></td><td><p>1227MHz</p></td></tr><tr><td class=tlgrey>Crysis 3</td><td><p>1113MHz</p></td><td><p>1177MHz</p></td></tr><tr><td class=tlgrey>Mordor</td><td><p>1126MHz</p></td><td><p>1164MHz</p></td></tr><tr><td class=tlgrey>Civilization: BE</td><td><p>1088MHz</p></td><td><p>1215MHz</p></td></tr><tr><td class=tlgrey>Dragon Age</td><td><p>1189MHz</p></td><td><p>1215MHz</p></td></tr><tr><td class=tlgrey>Talos Principle</td><td><p>1126MHz</p></td><td><p>1215MHz</p></td></tr><tr><td class=tlgrey>Far Cry 4</td><td><p>1101MHz</p></td><td><p>1164MHz</p></td></tr><tr><td class=tlgrey>Total War: Attila</td><td><p>1088MHz</p></td><td><p>1177MHz</p></td></tr><tr><td class=tlgrey>GRID Autosport</td><td><p>1151MHz</p></td><td><p>1190MHz</p></td></tr></tbody></table><p>Speaking of clockspeeds, taking a look at our average clockspeeds for GTX Titan X and GTX 980 showcases just why the 50% larger GM200 GPU only leads to an average performance advantage of 35% for the GTX Titan X. While the max boost bins are both over 1.2GHz, the GTX Titan has to back off far more often to stay within its power and thermal limits. The final clockspeed difference between the two cards depends on the game in question, but we’re looking at a real-world clockspeed deficit of 50-100MHz for GTX Titan X.</p><p><img alt="Idle Power Consumption" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph9059/72532.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>Starting off with idle power consumption, the GTX Titan X comes out strong as expected. Even at 8 billion transistors, NVIDIA is able to keep power consumption at idle very low, with all of our recent single-GPU NVIDIA cards coming in at 73-74W at the wall.</p><p><img alt="Load Power Consumption - Crysis 3" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph9059/72533.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="Load Power Consumption - FurMark" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph9059/72534.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>Meanwhile load power consumption for GTX Titan X is more or less exactly what we’d expect. With NVIDIA having nailed down their throttling mechanisms for Kepler and Maxwell, the GTX Titan X has a load power profile almost identical to the GTX 780 Ti, the closest equivalent GK110 card. Under Crysis 3 this manifests itself as a 20W increase in power consumption at the wall – generally attributable to the greater CPU load from GTX Titan X’s better GPU performance – while under FurMark the two cards are within 2W of each other.</p><p>Compared to the GTX 980 on the other hand, this is of course a sizable increase in power consumption. With a TDP difference on paper of 85W, the difference at the wall is an almost perfect match. GTX Titan X still offers Maxwell’s overall energy efficiency, delivering greatly superior performance for the power consumption, but this is a 250W card and it shows. Meanwhile the GTX Titan X’s power consumption also ends up being very close to the unrestricted R9 290X Uber, which in light of the Titan’s 44% 4K performance advantage further drives home the point about NVIDIA’s power efficiency lead at this time.</p><p><img alt="Idle GPU Temperature" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph9059/72535.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>With the same Titan cooler and same idle power consumption, it should come as no surprise that the GTX Titan X offers the same idle temperatures as its GK110 predecessors: a relatively cool 32C.</p><p><img alt="Load GPU Temperature - Crysis 3" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph9059/72536.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="Load GPU Temperature - FurMark" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph9059/72537.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>Moving on to load temperatures, the GTX Titan X has a stock temperature limit of 83C, just like the GTX 780 Ti. Consequently this is exactly where we see the card top out at under both FurMark and Crysis 3. 83C does lead to the card temperature throttling in most cases, though as we’ve seen in our look at average clockspeeds it’s generally not a big drop.</p><p><img alt="Idle Noise Levels" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph9059/72538.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>Last but not least we have our noise results. With the Titan cooler backing it, the GTX Titan X has no problem keeping quiet at idle. At 37.0db(A) it's technically the quietest card among our entire collection of high-end cards, and from a practical perspective is close to silent.</p><p><img alt="Load Noise Levels - Crysis 3" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph9059/72539.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p><img alt="Load Noise Levels - FurMark" src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph9059/72540.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>Much like GTX Titan X’s power profile, GTX Titan X’s noise profile almost perfectly mirrors the GTX 780 Ti. With the card hitting 51.3dB(A) under Crysis 3 and 52.4dB(A) under FurMark, it is respectively only 0.4dB and 0.1dB off from the GTX 780 Ti. From a practical perspective what this means is that the GTX Titan X isn’t quite the hushed card that was the GTX 980 – nor with a 250W TDP would we expect it to be – but for its chart-topping gaming performance it delivers some very impressive acoustics. The Titan cooler continues to serve NVIDIA well, allowing them to dissipate 250W in a blower without making a lot of noise in the process.</p><p>Overall then, from a power/temp/noise perspective the GTX Titan X is every bit as impressive as the original GTX Titan and its GTX 780 Ti sibling. Thanks to the Maxwell architecture and Titan cooler, NVIDIA has been able to deliver a 50% increase in gaming performance over the GTX 780 Ti without an increase in power consumption or noise, leading to NVIDIA once again delivering a flagship video card that can top the performance charts without unnecessarily sacrificing power consumption or noise.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZIZxgZhoq6GdXaPDqrDImmSgnZakv6SxjKCrsWWknsGiuoyxZKudpp6yuHuQbw%3D%3D</p><footer class=site-footer><span class=site-footer-credits>Made with <a href=https://gohugo.io/>Hugo</a>. © 2022. All rights reserved.</span></footer></section><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>